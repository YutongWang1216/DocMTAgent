Modern computers are so advanced that we don't even notice how bad their performance is.
Today, I would like to talk about this issue and the concept of "repairing" it in the field of neuroscience.
In 2011, on a night in Harlem when frost fell, that night left a deep impact on me.
I was discussing the power of holograms that will someday replace computers with a fellow student outside a bar at Columbia University, where I was studying computer science and neuroscience.
Our conversation reached its peak excitement when his smartphone lit up.
He took out his smartphone, looked at it, and started typing.
And looking up at me with just his eyes, he said, "Go on, I'm listening."
But of course, his gaze became vague and the meaning of that moment was lost.
At that moment, on the other side of the bar, another student was holding a smartphone and raising it to a group of friends.
They were showing Instagram photos while swiping, and laughing uncontrollably.
I began to think about how they were feeling happy about the same technology that I was feeling dissatisfied with.
As I thought about it, I realized that the "villain" was not the digital information itself, but simply the display device that was separating me from my friends, and on the other hand, it was what connected them.
They were connected around something, just like telling stories around a campfire, like our ancestors who developed social cognition. I think this tool exists for that purpose.
It should be an extension of physical functions.
Today's computers are experiencing the opposite.
When you are sending an email to your wife, composing a symphony, or comforting a friend, you are taking exactly the same actions.
While bending over, he operates the continuously appearing icons and menu buttons displayed in squares like this.
I think this is wrong. I believe we can start using much more "natural machines."
We should use machines that bring these tasks back to the real world.
We should use machines that expand perception by applying the principles of neuroscience, rather than limiting it.
Here, I have brought such a machine.
This is "Meta 2."
Let's give it a try.
Now, I can see all of you in front of me, and I can also see my own hands.
Alright, 3, 2, 1, let's dive into the immersive holographic experience. A very realistic hologram is right in front of me - now, it's floating in front of the headset I'm currently wearing.
Of course, what you are looking at could be shopping items or learning materials. You can use your hands to finely control and move them smoothly.
Iron Man would be proud as well.
I will show this to you shortly after.
(Applause) If you are thinking the same way as I am, you must be excited thinking about the possibilities of such technology. So, let's take a look at a few examples.
My mother is an architect, so naturally, what came to mind was to draw up building blueprints in a 3D space instead of 2D drawings.
My mother is now touching the images and choosing the interior design.
This was all filmed using a GoPro camera through headgear.
The next use case is a very personal one, the "Glass Brain" project conducted by Professor Adam Gazzaley at the University of California, San Francisco.
As a student of neuroscience, I have always dreamed of learning and remembering by using machines that allow me to touch and manipulate the diverse and complex structure of the brain.
What you are seeing now is augmented reality, but this is part of a more important concept - instead of limiting physical abilities through digital devices, the idea is to enhance them.
Here we go...
I believe that humanity will enter a transitional period in the next few years.
All digital information begins to be represented in the real world.
Imagine for a moment: storytellers, painters, neurosurgeons, interior designers, and us here - what significance do they hold for us?
What we as a social community should do is imagine how to create a new reality that expands human experiences, and not just gamify reality or clutter it with digital information.
I am very passionate about this.
Now, I will reveal a little secret.
Within about 5 years, these will all become thin glasses projecting holograms, although this is not a small device within about 5 years.
When we choose a smartphone, we don't pay much attention to the hardware itself and focus more on the basic software, but as a neuroscientist, I have always dreamed of creating what you might call a "mind's iOS."
It is very important to create this properly because we may end up spending at least as long with such a system as we do with the Windows screen interface.
I don't know about you, but living inside Windows is a scary thing.
To derive the most intuitive interface from all possibilities, we have made neuroscience the cornerstone of our design. Instead of designers battling in boardrooms, we have turned to neuroscience.
And the principle at the center of this is called the "minimal resistance neural pathway."
Constantly connecting the "mind's iOS" to the human brain - for the first time, the human brain controls that iOS.
In other words, we are trying to create computers that do not require learning how to use them.
We are creating a system where users naturally understand how to use it.
We will introduce the three main new design guidelines for the user experience that we have used.
The most important thing is that "the user is the OS."
Traditional systems composed of conventional files are complex and abstract, requiring even just to understand them to use your head first.
It goes against the "minimal resistance neural pathway."
However, in augmented reality, by placing a holographic TED panel here and a hologram email on the opposite side of the desk, spatial memory capacity adapts to this, allowing you to reach out and retrieve information.
Anything, from what the legal team requested from me before the presentation to the Tesla car I want to buy, can be displayed in hologram form.
Alright, with this, your brain has learned how to retrieve information.
The second guideline for the interface is "see and touch."
When a baby sees something they are interested in, what will they do first?
You will try to reach out and touch it, right?
"Natural machines" should function in this way.
The visual system receives basic stimuli from what is called proprioceptive sensation, which is a sensation that occurs deep within the body.
Therefore, by directly touching the work, you can not only control it better but also understand it more deeply.
Therefore, it is "see and touch."
However, just this alone is not sufficient as an experience.
Humans are primates who are inherently social creatures.
From there, the third guideline, namely the hologram version of the example of the campfire at the beginning, is derived.
The mirror neuron subsystem of primates shows that if they can see each other's faces and hands in three dimensions, they can cooperate and work together more effectively.
Please watch the video behind me, where two Meta users interact with the same hologram, exchanging glances without being distracted by the devices, and connecting through this object.
Now, let's try this again with neuroscience in mind.
Our favorite "mind's iOS."
Let's take one step further. Pick up this headset and place it on this spot next to the desk.
Now, I am here with all of you, and at this moment, we are connected.
As my spatial memory kicks in and I reach out to grab the headset, I realize that I am the operating system.
And as my proprioceptive sensation kicks in, I break down this headset into thousands of parts - touching the sensor scanning my hand.
But just watching this by myself is not enough, so now co-founder Ray will soon call on a 3D phone - Ray?
(Ringing) Hey Ray, how are you?
Everyone, I can see him in front of me in three dimensions.
With a realism like a photograph
(Applause) Thank you very much.
My mirror neuron system suggests that this will soon replace cell phones.
Ray, how are you doing?
Sounds good, we are in the middle of a live conversation now.
(Applause) Ray, I will now show you the holographic brain that you saw in the video earlier.
Everyone, this will not only change the phone but also change the way we work together.
Thank you very much.
Ray, thank you.
You're welcome.
(Applause) This is the message I found in that bar in 2011 - the future of computers is not confined to flat screens.
It's right here, within all of us.
(Applause) If I were to choose just one idea to leave with all of you today, it would be that "natural machines" are not just the future, but they are already here in 2016.
So all 100 staff members working at Meta - administrative staff, management, designers, and engineers - will throw away their monitor screens by TED2017 and truly use "natural machines."
Thank you very much.
(Applause) Thank you very much.
Thank you.
(Chris Anderson) But I would like to ask - there have been several demonstrations of augmented reality over the past few years, but
There is sometimes a discussion among engineers about whether they are actually looking at real objects on a large screen.
There was also a mention about the field of view, pointing out that in demos, a wider field of view can be drawn than what is actually seen when wearing the actual headset.
Is what you showed us actual footage?
Of course, it's the real thing.
Not only that, but when creating the video that was introduced, we especially made efforts to shoot through the lens of a GoPro camera.
I wanted everyone to experience the real experience seen through the headgear as a whole, just as it is, in a simulated experience.
Thank you for introducing me.
Thank you very much.
