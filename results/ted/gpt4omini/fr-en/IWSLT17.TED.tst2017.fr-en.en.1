Today's computers are so incredible that one does not realize how bad they really are.
I would like to talk to you today about this problem and how we can solve it with neuroscience.
First of all, I would like to take you back to Harlem on a freezing night in 2011 that deeply impacted me.
I was sitting at a bar not far from Columbia University, where I was studying computer science and neuroscience, and I was having a deep conversation with another student about the potential of holograms to one day replace computers.
Just as we were reaching the best moment of the conversation, of course, his phone lit up.
He takes it out, looks at it, and starts typing something.
Then he forces his eyes back on me and says, "Go on. I'm listening."
But of course, his eyes were vacant, and the moment had passed.
Meanwhile, in that bar, I saw another student holding his phone, this time towards a group.
He was scrolling through photos on Instagram, and those kids were laughing hysterically.
This dichotomy between my feeling of discomfort and the joy they felt about the same technology made me question things.
The more I thought about it, the more I realized that here, the problem was clearly not the digital information; it was only the position of use that separated me from my friend and brought those kids together.
They were connected around something just like our ancestors who enhanced their social knowledge by telling stories around the campfire.
I think that's exactly what tools should do.
Extending our bodies.
I think that today computers do the opposite.
Whether you send an email to your wife, compose a symphony, or console a friend, you do it in pretty much the same way.
You are leaning over these rectangles, typing on buttons, menus, and more rectangles.
I think that's the wrong way. I believe we can start using a more natural machine.
We should use machines that bring our work back into this world.
Machines that use the principles of neuroscience to extend our senses, rather than go against them.
It turns out that I actually have such a machine.
Her name is Meta 2.
Let's test it!
In front of me, I can see an audience, and I can see my hands.
And in three, two, one, we are going to see an immersive hologram appear; a very realistic hologram appears before me, coming from the glasses I am wearing.
Of course, it could be something we buy or learn, and I can use my hands to move them delicately.
I think Iron Man would be proud.
We will come back to that a little later.
Now, if you are like me, your mind is already stunned by the possibilities we have with this type of technology; let's take a look at a few of them.
My mother is an architect, so naturally the first thing I imagined was to design a building in 3D instead of using those 2D plans.
There, she touches the graphics and selects an interior decor.
Everything was filmed with a GoPro using our own glasses.
This next case is truly special to me; it concerns the brain glasses project by Professor Adam Gazzaley, provided by UCSF.
As a neuroscience student, I will always fantasize about the possibility of learning and memorizing these complex brain structures with a real machine; I could touch and play with these different brain structures.
What you see now is called augmented reality, but for me, it is part of a much larger story — a story about how we begin to extend our bodies through digital objects, rather than the other way around.
Now...
I believe that in the coming years, humanity will experience a change.
We are going to start layering an entire digital layer of information onto the real world.
Imagine for a moment what this would mean for storytellers, painters, neurosurgeons, interior designers, and perhaps for all of us here today.
And what we need to do as a community is to try and make the effort to imagine how we can create this new reality in a way that extends human experience, rather than gamifying our reality or cluttering it with digital information.
That is what truly excites me.
Now, I want to share a little secret with you.
In about five years — it's not the smallest device — in about five years, they will all look like bands of glass on our eyes that project holograms.
Just as we care little about the phone we buy for its technical features — we buy it for the operating system — as a neuroscientist, I have always dreamed of creating the "iOS of the mind," if you will.
It is very, very important to do things right, because we could live in these things for at least as long as the time spent with the Windows user interface.
And I don't know about you, but living inside Windows scares me.
To isolate the most intuitive interface from infinity, we use neuroscience to create our design principles, rather than a group of designers arguing in a meeting.
The principle on which we all rely is what is called the "Neural Path of Least Resistance."
Each time, we try to connect the iOS of our brain with our brain according to, for the very first time, our conditions.
In other words, we are trying to create a computer with no learning curve.
We are building a system that you have always known how to use.
Here is the first of three principles that we employ in this brand new user experience.
First of all, you are the operating system.
Traditional file systems are complex and abstract, requiring additional steps from your brain to decode them.
We disrupt the Neural Path of Least Resistance.
In the meantime, in augmented reality, you place your TED holographic panel right there, and your holographic email on the other side of the desk, and your enhanced spatial memory retrieves them.
You could place your holographic Tesla that you buy — or any model that my legal team told me to include.
Perfect. Your brain knows exactly how to bring it back.
We call the second interface principle "Touch to See."
What do babies do when they see something that catches their attention?
They try to reach it, to touch it.
This is exactly how the natural machine should work.
It turns out that the visual system has an essential boost from a sense called proprioception — it is the sense of our body’s limbs in space.
By directly touching our work, we will not only gain better control over it, but we will also understand it better.
And so, touch to see.
But that is not enough to feel things.
We are intrinsically social primates.
This brings me to our third principle, the holographic campfire from our first story.
Our mirror neuron system suggests that we can better connect with each other and with our work if we can see our faces and hands in 3D.
So if you look at the video behind me, you can see two Meta users playing with the same hologram, making eye contact, connected around this object, instead of being distracted by external devices.
Let's continue and try again with neuroscience in mind.
Once again, our favorite interface, the iOS of the mind.
I will now go further and grab this pair of glasses and leave it here next to the desk.
I am with you, right now, we are connected.
My spatial memory has kicked in, and I can grab it and place it back here, reminding myself that I am the operating system.
And my proprioception is activated, and I can go ahead and shatter these glasses into thousands of pieces and touch the sensor that is scanning my hand.
But that is not enough to see the objects alone; in a moment, co-founder Ray will call in 3D -- Ray?
Hi Ray, how's it going?
I can see this person entirely in front of me in 3D.
And it is quite realistic.
Thank you.
My mirror neuron system suggests that this will replace phones in no time.
Ray, how's it going?
Ray: Very well. We are live today.
MG: Ray, give the audience a gift of the holographic brain that we saw earlier.
This will not only replace phones, but it will also change the way we collaborate.
Thank you very much.
Thank you, Ray.
Ray: You're welcome.
MG: Well, here’s the message I discovered in a bar in 2011: the future of computers is not confined within one of these screens.
It is right there, within us.
If there is only one idea I can share today, it is that the natural machine is not the product of the future; it is right here in 2016.
That is why all of us at Meta, including the administrative staff, executives, designers, and engineers -- before TED2017, we are all going to toss our external monitors and replace them with machines that are truly and profoundly more natural.
Thank you very much.
Thank you, that's very kind.
Thank you all.
Chris Anderson: Well, explain one thing to me, because there were few demonstrations of augmented reality last year or previously right here.
And there is sometimes a debate among technologists about whether we are really seeing the actual object on the screen.
It's a field of vision problem. In a way, the technology shows a wider view than what you should see while wearing the glasses.
Have we seen real life?
MG: Absolutely real life.
And not only that, we took further steps to film with a GoPro using the real lenses, the various videos broadcasted.
We want to try to simulate the experience of the world that we see through the glasses, and not cut off any passage.
CA: Thank you very much for this presentation.
MG: Thank you very much, it was a pleasure.
