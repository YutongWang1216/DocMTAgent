Modern computers are so superior that we don't even notice how bad they can be.
Today, I would like to talk about this problem and how we, in neuroscience, address it by "repairing" it.
The night of a frosty Harlem in 2011, that night had a profound impact on me.
It was at a bar outside Columbia University, where I studied computer science and neuroscience, having a meaningful conversation with a classmate about the power of holograms that would one day replace computers.
As our conversation reached its peak, there, his smartphone lit up.
He took out his smartphone, turned his attention to it, and began typing.
He then looked up at me with just his eyes and said, "Go on, I'm listening."
But of course, his gaze became unfocused, and the significance of that moment was lost.
At that moment, on the other side of the bar, another student held up his smartphone to a group of friends.
They were laughing uproariously as they swiped through Instagram photos to show each other.
I began to think about how they felt happy with the same technology that I found frustrating.
As I thought about it, I realized that the culprit wasn't digital information itself, but rather, the display device that was putting distance between my friends and me, even as it connected them.
They were bonding around something, much like our ancestors who developed social cognition by telling stories around a campfire. I think this tool is meant for just that.
It should be an extension of bodily function.
With today's computers, the opposite is happening.
When you're emailing your wife, composing a symphony, or comforting a friend, you're engaging in essentially the same kind of behavior.
You are hunched over, manipulating the endlessly appearing icons and menu buttons displayed in this boxy manner.
I believe this is wrong, and I think we can start using much more "natural machines."
We should use machines that bring such tasks back to the real world.
We should employ machines that expand perception, not limit it, by applying the principles of neuroscience.
Well, I've brought just such a machine here.
This is the "Meta 2."
Let's give it a try.
Now, I can see all of you in front of me, and I can see my own hands as well.
Alright, three, two, one, I'm diving into the immersive hologram experience. A very realistic hologram is appearing right before my eyes - in front of the headset I'm wearing now.
Of course, what you see could be items to purchase or perhaps educational materials, and you can use your hands to control them precisely and manipulate them skillfully.
Even Iron Man would be proud of it, I think.
I will show you this again right after.
( Applause ) If you think like me, you're probably excited about the possibilities of what can be done with such technology. Let's take a look at a few examples then.
My mother is an architect, so what naturally came to mind was the ability to draw out building designs in three-dimensional space instead of on two-dimensional blueprints.
My mother is now touching the images to select interior finishes.
This was all filmed using GoPro cameras, through headgear.
The next use case is a very personal one, courtesy of Professor Adam Gazzaley at the University of California, San Francisco, conducting the "Glass Brain" project.
As a neuroscience student, I always dreamed of learning and memorizing as if I could touch and manipulate this diverse and complex brain structure using a machine.
What we are looking at now is augmented reality, but this is part of a more significant concept - the notion that, rather than limiting our physical capabilities, digital devices should enhance them.
Well...
I believe that in the coming years, humanity will face a turning point.
All digital information begins to manifest in the real world.
Just imagine for a moment, what would this mean for storytellers, painters, neurosurgeons, interior designers, and all of us here?
What we, as a societal collective, should do is imagine how to create new realities that augment the human experience, ensuring that we don't merely gamify reality or clutter it with digital information.
I am very passionate about this.
Now, let me share a little secret.
Within about five years, though they won't be small devices, within about five years, all of these will become like thin glasses that project holograms.
When we choose our smartphones, we don't focus too much on the hardware itself, but rather on the primary software, yet as a neuroscientist, I have always dreamed of, so to speak, creating the "iOS of the mind."
Creating this properly is very important, because we may end up spending as much time, if not longer, with such systems as we have with the interface of the Windows screen.
I don't know about you, but living inside a Windows environment is a scary thought.
From all possible options, we derived the most intuitive interface by making neuroscience the core of our design, rather than having designers battle it out in the boardroom.
And the principle at the core of this is what we call the "principle of least neural resistance."
Constantly connecting the "iOS of the mind" to the human brain - for the first time, the human brain controls that iOS.
In other words, we are trying to create a computer that requires no learning to use.
We are creating a system that users understand naturally how to use.
I will introduce the three main new design guidelines for user experience that we have adopted.
The most important thing is that "the user is the OS."
A system composed of conventional files is complex and abstract, and it first requires our brains to even understand it.
It is doing the opposite of the "principle of least neural resistance."
In augmented reality, however, placing a holographic TED panel here and a hologram mail on the other side of the desk allows spatial memory to adapt, enabling one to reach out and pull information towards them.
Anything can be displayed as a hologram, from the Tesla car you're thinking of buying to the legal team â€” what they asked of me prior to taking the stage.
Okay, now your brain has learned how to retrieve information.
The second guideline for the interface is "see and touch."
When a baby sees something that interests them, what do they do first?
They reach out and try to touch it, don't they?
A "natural machine" should work in exactly this way.
The visual system receives basic stimuli from proprioceptive sensations, which are sensations occurring deep within the body.
Therefore, by directly touching the creation, one can not only control it better but also understand it more deeply.
Therefore, it is "see and touch."
However, this alone is not sufficient for a full experience.
Humans are inherently social creatures, born as primates.
From there, the third guideline emerges - a holographic version of the opening campfire example is introduced.
The primate mirror neuron subsystem shows that if we can perceive each other's faces and hands in three dimensions, we can collaborate and work together more effectively.
Please look at the video behind me, showing two Meta users interacting with the same hologram, able to make eye contact and connect through the object without being distracted by the device.
Let's try this again, keeping neuroscience in mind.
Our favorite, the "iOS of the mind."
Let's take it one step further. I pick up this headset and place it in this spot next to the desk.
Right now, I am with all of you, and in this moment, we are connected.
As my spatial memory kicks in and I grab the headset to retrieve it, I realize that I am the operating system.
And as my proprioceptive senses kick in, I decompose this headset into thousands of parts - I touch the sensor that scans my hand.
But simply viewing this alone is insufficient, so now my co-founder Ray will soon be calling in on a 3D call -- Ray?
(Ringtone) Hey Ray, how are you?
Everyone, I can see him right here, in 3D.
with the realism of a photograph
(Applause) Thank you.
My mirror neuron system suggests that this will soon replace the mobile phone.
How are you doing, Ray?
Alright, we're in a live conversation now, aren't we?
(Ray, show everyone the hologram of the brain that we saw in the video earlier.)
Ladies and gentlemen, this won't just change the way we communicate over the phone, but also how we collaborate and work together.
Thank you.
Ray, thank you.
You're welcome.
This is the message I found in that bar in 2011. The future of computers is not confined to flat screens.
It's right here, inside of us.
If I were to leave you with just one idea today, it would be that "natural machines" are not a thing of the future, but are already here, in 2016.
So by TED2017, all 100 employees at Meta -- administrative staff, management, designers, engineers -- will have ditched their monitor screens and will truly be using "natural machines."
Thank you.
Thank you.
Thank you
(Chris Anderson) So let me ask you -- there've been a number of demos of augmented reality over the past few years,
There has also been some debate among technicians about whether we're actually seeing the real thing on a large screen.
There were also comments about the field of view: that in demonstrations, it tends to appear wider than what you actually see when wearing the headset.
Was that the actual footage you showed us?
Of course, it's the real deal.
Not only that, but when we created the video I presented, we took particular care to film through the lens of a GoPro camera.
I wanted you to fully experience, through the headset, the genuine experience as it is, in its entirety.
Thank you for introducing me.
Thank you.
