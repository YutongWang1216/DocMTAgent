Today's computers are so amazing that we tend to overlook just how terrible they actually are.
Today, I want to talk to you about this problem and how we can use neuroscience to address it.
First, I want to take you back to a cold night in Harlem in 2011, a night that had profound significance for me.
I was sitting in a bar next to Columbia University, where I majored in computer science and neuroscience, engaged in a fascinating conversation with a classmate about the potential of holography to one day replace computers.
Just as our conversation reached a particularly engaging point, as expected, his phone rang.
He picked up his phone, bowed his head, and began typing.
And he would occasionally look up at me and say, "Go on, I'm listening."
But it was clear that his attention was not focused, and a wonderful moment passed in the blink of an eye.
Meanwhile, across the bar, I noticed another student with his phone, this time with a small crowd gathered around the screen.
He was scrolling through photos on Instagram, and these kids were laughing out loud.
Confronted with the same technology, they found such joy, while I felt immense frustration, and this stark contrast immediately set me thinking.
As I delved deeper into my thoughts, I became increasingly aware that the issue here was clearly not the digital information itself, but rather the location of its presentation, which was dividing me from my friend yet bringing these kids together.
It was clear that they were being bonded by something, much like our ancestors had evolved their social cognition, such as storytelling around a campfire.
I believe this is precisely what tools are meant to do.
They should extend our bodily functions.
I believe that today, computers are doing precisely the opposite.
Whether you're sending an email to your wife, or composing for a symphony, or simply consoling a friend, you're almost always doing it in the same way.
You hunch over these boxes, fiddling with buttons and menus, and more boxes appear.
I feel that this is a mistake, and I think we can begin to use a machine in a much more natural way.
The machines we use should be able to bring our work back into the real world.
We should use machines that can leverage the principles of neuroscience to extend our senses, rather than confine them.
Now I happen to have one such machine right here.
It's called the Meta 2.
Let's give it a try.
Now I can see the audience, and I can also see my hands.
On the count of three, two, one, we will see a holographic image appear, a very realistic holography appearing in front of me, in front of the glasses I am now wearing.
Of course, this could be anything we're about to purchase or learn about, and I can effortlessly manipulate its movement with my hands.
And I think Iron Man would be proud.
We'll come back to this later.
(Applause from the audience) If you're like me, you've already started thinking about what you could do with this kind of technology. Let's take a look at some examples.
My mother is an architect, so naturally, the first thing I imagine is drawing a building in 3D, rather than with these flat floor plans.
In fact, she's now touching the design, contemplating choices for interior decoration.
All of this is being captured by the GoPro in my glasses.
The next use case is a personal one for me: Professor Adam Gazzaley's Glass Brain project, for which I thank UCSF for the permission.
As a student of neuroscience, I'm always amazed at the ability to learn and memorize these complex brain structures with a tangible machine, allowing me to touch and manipulate different parts of the brain.
What you're seeing now is called augmented reality, but to me, it's just part of a bigger story -- one about how we're starting to use digital devices to extend our bodies, rather than confine our bodily functions.
So --
In the coming years, humanity will undergo a transformation, I believe.
We will begin to overlay a digital information layer onto the real world.
Take a moment to imagine what this means for storytellers, for painters, for brain surgeons, for interior decorators, perhaps for all of us here today, what it truly signifies.
What I think we need to do as a group is really try and strive to envision how we create this new reality in a way that extends the human experience, rather than gamifying our reality or conflating it with digital information.
That is precisely what I am very interested in doing.
Now, I want to let you in on a little secret.
Within about five years -- this won't be the smallest device -- within about five years, all of this will look like a strip of glasses placed in front of your eyes, capable of projecting holographic images.
Just as we don't much care about the hardware specifications of different phones — we choose based on the operating system — as a neuroscientist, I've always dreamed of building a brain-based iOS, if you will.
What's very, very important is that we get this right, because these things may well stay with us no less than the time we spent with the Windows graphical user interface.
I don't know about you, but the idea of living inside a Windows system is somewhat unsettling to me.
To isolate the most intuitive touch interface to infinity, we use neuroscience to guide our design, rather than leaving a bunch of designers to bicker in a design studio.
The principle that guides our evolution is called "the path of least resistance neural pathways."
At every moment of change, we connect the brain's iOS system to our minds, for the first time, in the language of our brains.
In other words, we are attempting to create a computer with a zero learning curve.
We are building a system that you already know how to use.
These are the first three design principles we apply in this new form of user experience.
First, you are the operating system.
Traditional file systems are complex and abstract, requiring your brain to take extra steps to decode them.
We are taking the opposite approach of "the path of least resistance neural pathways."
Meanwhile, in augmented reality, you could certainly place your holographic TED display over here, your holographic mail on the other side of the table, your spatial memory evolved just right to precisely retrieve this information.
You could put the holography of the Tesla you're shopping for right here — or any number of modalities my legal team tells me I'm allowed to say before coming on stage.
( Audience laughter ) Great, your brains do know how to come back to reality.
The second interface principle we call "touch visible."
What do babies do when they see something that interests them?
They try to reach out and grab it.
Natural machines work in the same way.
In fact, the visual system gets a very basic boost, which we can call proprioception — that's the sense of where different parts of our body are in space.
By directly engaging with what we're working on, we not only gain better control over it, but also achieve a deeper understanding of it.
This is what we call "touch visible."
But simply experiencing things ourselves is not enough.
We are social primates.
This brings me to our third guideline, the "Holographic Campfire," inspired by our first story:
Our mirror neurons suggest that we could be more connected to each person and to our work if we could see holograms of everyone's faces and hands.
So, if you look at the video behind me, you can see two Meta users interacting with the same holographic image, making eye contact, focusing on the object, rather than being distracted by external devices.
Let's try again with the concepts of neuroscience in mind.
Once again, our favorite interface, the iOS of the brain.
I'm now going to step forward, walk up to the front and pick up these glasses. Then I'll just place them here on the table.
I am now in a moment with you, and we are being connected together.
My spatial memory is at work, allowing me to go over, grab it, and then bring it back here, reminding myself that I am the operating system.
Now my proprioception is at work, allowing me to go over and shatter these glasses into thousands of pieces, then touch the sensors that are scanning my hand right at this moment.
But simply seeing these isn't enough, so shortly, my co-founder Ryan will be calling me on a 3D call — Ryan?
Hi, Ryan, how are you?
Ladies and gentlemen, I can see this person appearing in front of me as a three-dimensional projection.
And his image is incredibly lifelike.
(Applause from the audience) Thank you.
My mirror neurons indicate that this will replace telephones in the near future.
Hi, Ryan, how are you?
Ryan: I'm good. We can finally do a live demo.
(Applause from the audience) Ryan, give everyone a little holographic brain, the kind we saw in the short film earlier, as a token of appreciation.
Ladies and gentlemen, this won't just change the way we make calls, it will also transform how we collaborate.
Thank you very much.
Thank you, Ryan.
Ryan: You're welcome.
Myron Groisser: So, here's what I learned in that bar in 2011: The future of computing is not locked inside these screens.
But it's here, inside our bodies.
So if I could leave you with one idea today, it's that natural machines aren't just a vision of the future; they're here, in 2016.
That's why at Meta, over a hundred employees, including executives, managers, designers, engineers -- before TED 2017, we will be getting rid of our external displays, and replacing them with something truly more natural.
Thank you very much.
(Applause from the audience) Thank you.
Thank you all.
Chris Anderson: I have a question. There were already many demonstrations of holography that appeared last year.
There's sometimes a debate in the tech world about whether we're actually seeing things truly on these screens.
This is one of the issues in this field, where in a sense, the technology is presenting a wider perspective than what you actually see through the glasses.
Did we just see a true representation?
Myron Groisser: Absolutely a true representation.
Furthermore, we used additional measurement techniques, filming through the actual lenses with a GoPro, resulting in the various clips you've seen here.
We want to try and make the experience of seeing things through the glasses more real, not just a partial view, but a true representation of the world.
CA: Thank you very much for your demonstration.
MG: Thank you very much.
